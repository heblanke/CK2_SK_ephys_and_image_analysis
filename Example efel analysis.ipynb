{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import efel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy\n",
    "from scipy.signal import find_peaks\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b322947b60cc426",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#use neo to import either voltage or current clamp data in the correct, scaled units!\n",
    "def load_neo_file(file_name, **kwargs):\n",
    "    import neo\n",
    "    reader = neo.io.get_io(file_name)\n",
    "    blocks = reader.read(**kwargs)\n",
    "    new_blocks = []\n",
    "    for bl in blocks:\n",
    "        new_segments = []\n",
    "        for seg in bl.segments:\n",
    "            traces = []\n",
    "            count_traces = 0\n",
    "            analogsignals = seg.analogsignals\n",
    "\n",
    "            for sig in analogsignals:\n",
    "                traces.append({})\n",
    "                traces[count_traces]['T'] = sig.times.rescale('ms').magnitude\n",
    "                #need to write an if statement here for conversion\n",
    "                try:\n",
    "                    traces[count_traces]['A'] = sig.rescale('pA').magnitude\n",
    "                except:\n",
    "                    traces[count_traces]['V'] = sig.rescale('mV').magnitude\n",
    "                count_traces += 1\n",
    "            new_segments.append(traces)\n",
    "        #new_blocks.append(efel_segments)\n",
    "    return new_segments\n",
    "\n",
    "#Write a function to analyze an indiviudal feature for batch analysis from the efel package. This function will return a table with the feature values for each trace in the file.\n",
    "def analyze_feature(path, feature):\n",
    "    table2 = []\n",
    "    os.chdir(path)\n",
    "    for filename in os.listdir():\n",
    "        table = pd.DataFrame(columns=[feature])     #create a table that has columns with the name you want\n",
    "        table.name = feature                        #the tables name\n",
    "        if filename.endswith(\".axgd\") or filename.endswith(\".axgx\"):    #check for the filetype\n",
    "            [traces] = efel.io.load_neo_file(filename, stim_start=500, stim_end=1500)    #load the trace, and define stim start and stop\n",
    "            for data in traces:    #loop through these guys\n",
    "                #table.rename(columns={feature:filename}, inplace=True) #renaming the columns with the correct file !\n",
    "                feature_values = efel.getFeatureValues(data, [feature], raise_warnings=None)[0]  #this is the feature extraction\n",
    "                if feature_values[feature] is not None:\n",
    "                    # Define the parameters for detection\n",
    "                    efel.api.setThreshold(-10) # Voltage threshold for detection\n",
    "                    efel.api.setDerivativeThreshold(10) # dV/dt threshold for detection\n",
    "                    efel.setIntSetting('strict_stiminterval', True)\n",
    "                    length = len(table)\n",
    "                    table.loc[length, feature] = feature_values[feature][0]\n",
    "\n",
    "                else:\n",
    "                    efel.api.setThreshold(-10) # Voltage threshold for detection\n",
    "                    efel.api.setDerivativeThreshold(20) # dV/dt threshold for detection\n",
    "                    efel.setIntSetting('strict_stiminterval', True)\n",
    "                    length = len(table)\n",
    "                    table.loc[length, feature] = feature_values[feature]\n",
    "\n",
    "            table2.append(table)\n",
    "            df_concat = pd.concat(table2, axis=1)\n",
    "            table.rename(columns={feature:filename}, inplace=True) #renaming the columns with the correct file !\n",
    "            #block of code to combine all of the generated excel workbooks into a single workbook\n",
    "            df_concat.to_excel(feature + 'master_file.xlsx', index=False)\n",
    "    Current_injected = np.linspace(-100.0, 500.0, num=61)\n",
    "    table2 = df_concat.assign(Current_injected=Current_injected)\n",
    "    #lineplot = df_concat.plot()\n",
    "    #sns_lineplot = sns.relplot(data = table2, x = \"Spikecount_stimint\", y = 'Current_injected', kind=\"line\")\n",
    "    return(df_concat)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b223b91508c07c2a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cc_path = os.getcwd()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec3b6397a16c9bd1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#these code are well documented on efels github page. With strong documentation. These code are only used for the evoked spikes. All spontaneous firing code can be found in the \"Example Files\" folder. Here we use a steeper threshold for the detection of spikes. \n",
    "#these code return excel sheets that will be saved in the path that you are currently in with all of the data. I have included a few example files to show you how to use the code.\n",
    "os.chdir(cc_path)\n",
    "f_i = analyze_feature(cc_path, feature='Spikecount_stimint')\n",
    "# analyze_feature(cc_path, feature='ISI_CV')\n",
    "# analyze_feature(cc_path, feature='time_to_first_spike')\n",
    "# \n",
    "# analyze_feature(cc_path, feature='mean_frequency')\n",
    "# analyze_feature(cc_path, feature='steady_state_voltage_stimend')\n",
    "# analyze_feature(cc_path, feature='doublet_ISI')\n",
    "# analyze_feature(cc_path, feature='amp_drop_first_last')\n",
    "# analyze_feature(cc_path, feature='spike_half_width')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "487e29758669a00f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#set spike count stim int "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea221ac8afdfb643",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sns.lineplot(data = f_i)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "704f555807e7bb84",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9e52c79b00dd5de3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
